{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckqru9KQrXbZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z49fPURYa5EZ",
        "outputId": "4ea38219-7110-4205-b90e-1d03e05fa548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'assignment3-21-robustnet-1'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 45 (delta 14), reused 26 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (45/45), done.\n"
          ]
        }
      ],
      "source": [
        "#Clone the repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Ei3cusrbj8K",
        "outputId": "884ff31e-bdb5-4ad8-f5c9-3531ab805ebc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/assignment3-21-robustnet-1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/assignment3-21-robustnet-1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgqVd9e3bmSX",
        "outputId": "4661cec8-088b-4e4b-9562-ac54d104df13"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.11.1+cu111)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->-r requirements.txt (line 5)) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Ax_Y_OAHgjo_"
      },
      "outputs": [],
      "source": [
        "#The attack is in the file carlini_wagner_l2.py\n",
        "from carlini_wagner_l2 import (\n",
        "   carlini_wagner_l2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VI-ktDrYH-R",
        "outputId": "8ece3fd6-4a58-4632-e015-9462170051c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
              "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
              "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#!/usr/bin/env python3 \n",
        "import os\n",
        "import argparse\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from attacks import *\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "valid_size = 1024 \n",
        "batch_size = 32 \n",
        "criterion = nn.NLLLoss()\n",
        "'''Basic neural network architecture (from pytorch doc).'''\n",
        "class Net(nn.Module):\n",
        "\n",
        "    model_file=\"models/default_model.pth\"\n",
        "    '''This file will be loaded to test your model. Use --model-file to load/store a different model.'''\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "        return x\n",
        "    \n",
        "\n",
        "    \n",
        "\n",
        "    def save(self, model_file):\n",
        "        '''Helper function, use it to save the model weights after training.'''\n",
        "        torch.save(self.state_dict(), model_file)\n",
        "\n",
        "    def load(self, model_file):\n",
        "        self.load_state_dict(torch.load(model_file, map_location=torch.device(device)))\n",
        "\n",
        "        \n",
        "    def load_for_testing(self, project_dir='./'):\n",
        "        '''This function will be called automatically before testing your\n",
        "           project, and will load the model weights from the file\n",
        "           specify in Net.model_file.\n",
        "           \n",
        "           You must not change the prototype of this function. You may\n",
        "           add extra code in its body if you feel it is necessary, but\n",
        "           beware that paths of files used in this function should be\n",
        "           refered relative to the root of your project directory.\n",
        "        '''        \n",
        "        self.load(os.path.join(project_dir, Net.model_file))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####### Testing ############\n",
        "def test_natural(net, test_loader):\n",
        "    '''Basic testing function.'''\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for i,data in enumerate(test_loader, 0):\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = net(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return 100 * correct / total\n",
        "    \n",
        "######################## Attack Testing ########################\n",
        "\n",
        "\n",
        "def test_carlini_wagner(net,test_loader):\n",
        "  correct = 0\n",
        "  for i,data in enumerate(test_loader, 0):\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            adv_data = images.clone().detach().to(device)\n",
        "            # calculate outputs by running images through the network\n",
        "            adv_data.requires_grad = True\n",
        "            outputs = net(adv_data)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, nat_pred = torch.max(outputs.data, 1)\n",
        "            if nat_pred.item() != labels.item():\n",
        "              continue\n",
        "            #if test sample is correctly predicted\n",
        "            loss = criterion(outputs, labels)\n",
        "            net.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            data_grad = adv_data.grad.data\n",
        "            adv_data = carlini_wagner_l2(net,images,10,targeted=False,y=nat_pred)\n",
        "            output = net(adv_data)\n",
        "            _,adv_pred = torch.max(output.data, 1)\n",
        "            if adv_pred.item() == labels.item():\n",
        "              correct+=1\n",
        "            print(\"Test num \"+str(i))\n",
        "  final_acc = correct/float(len(test_loader))\n",
        "  print(\"\\tTest Accuracy = {} / {} = {}\".format( correct, len(test_loader), final_acc))\n",
        "  return 100*final_acc\n",
        "\n",
        "\n",
        "\n",
        "##########################################\n",
        "\n",
        "def get_train_loader(dataset, valid_size=1024, batch_size=32):\n",
        "    '''Split dataset into [train:valid] and return a DataLoader for the training part.'''\n",
        "\n",
        "    indices = list(range(len(dataset)))\n",
        "    train_sampler = torch.utils.data.SubsetRandomSampler(indices[valid_size:])\n",
        "    train = torch.utils.data.DataLoader(dataset, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "    return train\n",
        "\n",
        "def get_validation_loader(dataset, valid_size=1024, batch_size=32):\n",
        "    '''Split dataset into [train:valid] and return a DataLoader for the validation part.'''\n",
        "\n",
        "    indices = list(range(len(dataset)))\n",
        "    valid_sampler = torch.utils.data.SubsetRandomSampler(indices[:valid_size])\n",
        "    valid = torch.utils.data.DataLoader(dataset, sampler=valid_sampler, batch_size=batch_size)\n",
        "\n",
        "    return valid\n",
        "net = Net()\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzLF4cjGZ1KS",
        "outputId": "28d28c6e-5dab-4e64-8b6d-df0179d52ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Model natural accuracy (valid): 61.81640625\n"
          ]
        }
      ],
      "source": [
        "cifar = torchvision.datasets.CIFAR10('./data/', download=True, transform=transforms.ToTensor())\n",
        "valid_loader = get_validation_loader(cifar, valid_size, 1)  # batch size one for attack test otherwise put 32\n",
        "net.load(\"models/basic_model.pth\")\n",
        "acc = test_natural(net, valid_loader)\n",
        "print(\"Model natural accuracy (valid): {}\".format(acc))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFxuNPXZu0_3",
        "outputId": "ca22b598-adb4-4f2f-fbd7-91889234125f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test num 2\n",
            "Test num 3\n",
            "Test num 5\n",
            "Test num 7\n",
            "Test num 8\n",
            "Test num 10\n",
            "Test num 16\n",
            "Test num 17\n",
            "Test num 18\n",
            "Test num 19\n",
            "Test num 21\n",
            "Test num 22\n",
            "Test num 23\n",
            "Test num 25\n",
            "Test num 26\n",
            "Test num 29\n",
            "Test num 30\n",
            "Test num 31\n",
            "Test num 33\n",
            "Test num 34\n",
            "Test num 35\n",
            "Test num 36\n",
            "Test num 41\n",
            "Test num 43\n",
            "Test num 44\n",
            "Test num 45\n",
            "Test num 46\n",
            "Test num 48\n",
            "Test num 50\n",
            "Test num 52\n",
            "Test num 53\n",
            "Test num 54\n",
            "Test num 55\n",
            "Test num 57\n",
            "Test num 60\n",
            "Test num 61\n",
            "Test num 62\n",
            "Test num 64\n",
            "Test num 66\n",
            "Test num 68\n",
            "Test num 69\n",
            "Test num 71\n",
            "Test num 72\n",
            "Test num 75\n",
            "Test num 76\n",
            "Test num 77\n",
            "Test num 80\n",
            "Test num 82\n",
            "Test num 83\n",
            "Test num 87\n",
            "Test num 88\n",
            "Test num 89\n",
            "Test num 91\n",
            "Test num 92\n",
            "Test num 93\n",
            "Test num 95\n",
            "Test num 96\n",
            "Test num 97\n",
            "Test num 98\n",
            "Test num 103\n",
            "Test num 104\n",
            "Test num 108\n",
            "Test num 109\n",
            "Test num 110\n",
            "Test num 113\n",
            "Test num 114\n",
            "Test num 116\n",
            "Test num 117\n",
            "Test num 118\n",
            "Test num 119\n",
            "Test num 120\n",
            "Test num 121\n",
            "Test num 122\n",
            "Test num 123\n",
            "Test num 125\n",
            "Test num 127\n",
            "Test num 128\n",
            "Test num 130\n",
            "Test num 131\n",
            "Test num 132\n",
            "Test num 133\n",
            "Test num 136\n",
            "Test num 137\n",
            "Test num 139\n",
            "Test num 140\n",
            "Test num 141\n",
            "Test num 142\n",
            "Test num 143\n",
            "Test num 144\n",
            "Test num 146\n",
            "Test num 147\n",
            "Test num 149\n",
            "Test num 150\n",
            "Test num 151\n",
            "Test num 152\n",
            "Test num 154\n",
            "Test num 155\n",
            "Test num 156\n",
            "Test num 157\n",
            "Test num 160\n",
            "Test num 161\n",
            "Test num 162\n",
            "Test num 163\n",
            "Test num 164\n",
            "Test num 165\n",
            "Test num 168\n",
            "Test num 169\n",
            "Test num 174\n",
            "Test num 175\n",
            "Test num 177\n",
            "Test num 179\n",
            "Test num 180\n",
            "Test num 182\n",
            "Test num 183\n",
            "Test num 184\n",
            "Test num 185\n",
            "Test num 186\n",
            "Test num 187\n",
            "Test num 188\n",
            "Test num 190\n",
            "Test num 191\n",
            "Test num 192\n",
            "Test num 193\n",
            "Test num 194\n",
            "Test num 196\n",
            "Test num 197\n",
            "Test num 199\n",
            "Test num 201\n",
            "Test num 203\n",
            "Test num 204\n",
            "Test num 206\n",
            "Test num 207\n",
            "Test num 209\n",
            "Test num 210\n",
            "Test num 212\n",
            "Test num 214\n",
            "Test num 215\n",
            "Test num 216\n",
            "Test num 217\n",
            "Test num 218\n",
            "Test num 219\n",
            "Test num 220\n",
            "Test num 221\n",
            "Test num 222\n",
            "Test num 224\n",
            "Test num 226\n",
            "Test num 227\n",
            "Test num 228\n",
            "Test num 229\n",
            "Test num 231\n",
            "Test num 232\n",
            "Test num 238\n",
            "Test num 240\n",
            "Test num 241\n",
            "Test num 243\n",
            "Test num 248\n",
            "Test num 250\n",
            "Test num 252\n",
            "Test num 253\n",
            "Test num 254\n",
            "Test num 255\n",
            "Test num 257\n",
            "Test num 259\n",
            "Test num 261\n",
            "Test num 262\n",
            "Test num 263\n",
            "Test num 264\n",
            "Test num 266\n",
            "Test num 267\n",
            "Test num 268\n",
            "Test num 269\n",
            "Test num 270\n",
            "Test num 271\n",
            "Test num 273\n",
            "Test num 276\n",
            "Test num 277\n",
            "Test num 278\n",
            "Test num 279\n",
            "Test num 282\n",
            "Test num 283\n",
            "Test num 284\n",
            "Test num 287\n",
            "Test num 288\n",
            "Test num 290\n",
            "Test num 291\n",
            "Test num 292\n",
            "Test num 294\n",
            "Test num 295\n",
            "Test num 297\n",
            "Test num 298\n",
            "Test num 299\n",
            "Test num 300\n",
            "Test num 303\n",
            "Test num 304\n",
            "Test num 310\n",
            "Test num 311\n",
            "Test num 312\n",
            "Test num 314\n",
            "Test num 315\n",
            "Test num 318\n",
            "Test num 321\n",
            "Test num 322\n",
            "Test num 323\n",
            "Test num 324\n",
            "Test num 325\n",
            "Test num 326\n",
            "Test num 329\n",
            "Test num 330\n",
            "Test num 331\n",
            "Test num 332\n",
            "Test num 333\n",
            "Test num 335\n",
            "Test num 337\n",
            "Test num 338\n",
            "Test num 339\n",
            "Test num 340\n",
            "Test num 341\n",
            "Test num 346\n",
            "Test num 347\n",
            "Test num 349\n",
            "Test num 353\n",
            "Test num 354\n",
            "Test num 355\n",
            "Test num 356\n",
            "Test num 357\n",
            "Test num 358\n",
            "Test num 359\n",
            "Test num 360\n",
            "Test num 364\n",
            "Test num 368\n",
            "Test num 373\n",
            "Test num 378\n",
            "Test num 379\n",
            "Test num 381\n",
            "Test num 382\n",
            "Test num 383\n",
            "Test num 384\n",
            "Test num 385\n",
            "Test num 386\n",
            "Test num 387\n",
            "Test num 388\n",
            "Test num 389\n",
            "Test num 391\n",
            "Test num 393\n",
            "Test num 398\n",
            "Test num 400\n",
            "Test num 401\n",
            "Test num 402\n",
            "Test num 404\n",
            "Test num 405\n",
            "Test num 406\n",
            "Test num 407\n",
            "Test num 408\n",
            "Test num 409\n",
            "Test num 412\n",
            "Test num 413\n",
            "Test num 414\n",
            "Test num 415\n",
            "Test num 417\n",
            "Test num 421\n",
            "Test num 423\n",
            "Test num 424\n",
            "Test num 426\n",
            "Test num 427\n",
            "Test num 428\n",
            "Test num 429\n",
            "Test num 432\n",
            "Test num 435\n",
            "Test num 436\n",
            "Test num 437\n",
            "Test num 438\n",
            "Test num 439\n",
            "Test num 440\n",
            "Test num 441\n",
            "Test num 442\n",
            "Test num 443\n",
            "Test num 445\n",
            "Test num 446\n",
            "Test num 447\n",
            "Test num 451\n",
            "Test num 452\n",
            "Test num 453\n",
            "Test num 454\n",
            "Test num 456\n",
            "Test num 457\n",
            "Test num 458\n",
            "Test num 459\n",
            "Test num 460\n",
            "Test num 461\n",
            "Test num 462\n",
            "Test num 464\n",
            "Test num 467\n",
            "Test num 468\n",
            "Test num 469\n",
            "Test num 471\n",
            "Test num 473\n",
            "Test num 478\n",
            "Test num 479\n",
            "Test num 480\n",
            "Test num 481\n",
            "Test num 483\n",
            "Test num 484\n",
            "Test num 485\n",
            "Test num 487\n",
            "Test num 489\n",
            "Test num 490\n",
            "Test num 491\n",
            "Test num 492\n",
            "Test num 493\n",
            "Test num 494\n",
            "Test num 495\n",
            "Test num 496\n",
            "Test num 498\n",
            "Test num 502\n",
            "Test num 504\n",
            "Test num 505\n",
            "Test num 506\n",
            "Test num 507\n",
            "Test num 508\n",
            "Test num 512\n",
            "Test num 513\n",
            "Test num 514\n",
            "Test num 517\n",
            "Test num 518\n",
            "Test num 522\n",
            "Test num 523\n",
            "Test num 524\n",
            "Test num 526\n",
            "Test num 527\n",
            "Test num 528\n",
            "Test num 529\n",
            "Test num 530\n",
            "Test num 533\n",
            "Test num 534\n",
            "Test num 535\n",
            "Test num 537\n",
            "Test num 539\n",
            "Test num 540\n",
            "Test num 546\n",
            "Test num 547\n",
            "Test num 548\n",
            "Test num 549\n",
            "Test num 550\n",
            "Test num 551\n",
            "Test num 552\n",
            "Test num 553\n",
            "Test num 554\n",
            "Test num 556\n",
            "Test num 557\n",
            "Test num 558\n",
            "Test num 559\n",
            "Test num 560\n",
            "Test num 561\n",
            "Test num 562\n",
            "Test num 563\n",
            "Test num 564\n",
            "Test num 565\n",
            "Test num 568\n",
            "Test num 569\n",
            "Test num 571\n",
            "Test num 572\n",
            "Test num 573\n",
            "Test num 574\n",
            "Test num 575\n",
            "Test num 576\n",
            "Test num 579\n",
            "Test num 581\n",
            "Test num 582\n",
            "Test num 584\n",
            "Test num 589\n",
            "Test num 590\n",
            "Test num 591\n",
            "Test num 594\n",
            "Test num 598\n",
            "Test num 603\n",
            "Test num 604\n",
            "Test num 607\n",
            "Test num 609\n",
            "Test num 610\n",
            "Test num 611\n",
            "Test num 612\n",
            "Test num 613\n",
            "Test num 614\n",
            "Test num 615\n",
            "Test num 618\n",
            "Test num 619\n",
            "Test num 621\n",
            "Test num 622\n",
            "Test num 623\n",
            "Test num 624\n",
            "Test num 625\n",
            "Test num 626\n",
            "Test num 628\n",
            "Test num 630\n",
            "Test num 631\n",
            "Test num 633\n",
            "Test num 634\n",
            "Test num 635\n",
            "Test num 637\n",
            "Test num 638\n",
            "Test num 640\n",
            "Test num 644\n",
            "Test num 645\n",
            "Test num 649\n",
            "Test num 650\n",
            "Test num 651\n",
            "Test num 652\n",
            "Test num 653\n",
            "Test num 655\n",
            "Test num 656\n",
            "Test num 657\n",
            "Test num 659\n",
            "Test num 660\n",
            "Test num 661\n",
            "Test num 663\n",
            "Test num 665\n",
            "Test num 666\n",
            "Test num 667\n",
            "Test num 668\n",
            "Test num 669\n",
            "Test num 670\n",
            "Test num 671\n",
            "Test num 672\n",
            "Test num 676\n",
            "Test num 677\n",
            "Test num 678\n",
            "Test num 679\n",
            "Test num 682\n",
            "Test num 684\n",
            "Test num 687\n",
            "Test num 690\n",
            "Test num 691\n",
            "Test num 693\n",
            "Test num 695\n",
            "Test num 698\n",
            "Test num 700\n",
            "Test num 702\n",
            "Test num 703\n",
            "Test num 705\n",
            "Test num 706\n",
            "Test num 707\n",
            "Test num 708\n",
            "Test num 711\n",
            "Test num 712\n",
            "Test num 714\n",
            "Test num 716\n",
            "Test num 720\n",
            "Test num 723\n",
            "Test num 724\n",
            "Test num 725\n",
            "Test num 726\n",
            "Test num 728\n",
            "Test num 729\n",
            "Test num 731\n",
            "Test num 732\n",
            "Test num 734\n",
            "Test num 735\n",
            "Test num 736\n",
            "Test num 739\n",
            "Test num 740\n",
            "Test num 741\n",
            "Test num 742\n",
            "Test num 744\n",
            "Test num 747\n",
            "Test num 748\n",
            "Test num 749\n",
            "Test num 751\n",
            "Test num 752\n",
            "Test num 755\n",
            "Test num 757\n",
            "Test num 758\n",
            "Test num 759\n",
            "Test num 761\n",
            "Test num 762\n",
            "Test num 763\n",
            "Test num 766\n",
            "Test num 767\n",
            "Test num 770\n",
            "Test num 772\n",
            "Test num 774\n",
            "Test num 776\n",
            "Test num 778\n",
            "Test num 780\n",
            "Test num 781\n",
            "Test num 784\n",
            "Test num 785\n",
            "Test num 788\n",
            "Test num 790\n",
            "Test num 792\n",
            "Test num 793\n",
            "Test num 794\n",
            "Test num 797\n",
            "Test num 799\n",
            "Test num 801\n",
            "Test num 802\n",
            "Test num 803\n",
            "Test num 804\n",
            "Test num 805\n",
            "Test num 807\n",
            "Test num 808\n",
            "Test num 809\n",
            "Test num 810\n",
            "Test num 811\n",
            "Test num 814\n",
            "Test num 816\n",
            "Test num 817\n",
            "Test num 818\n",
            "Test num 820\n",
            "Test num 821\n",
            "Test num 825\n",
            "Test num 826\n",
            "Test num 827\n",
            "Test num 828\n",
            "Test num 830\n",
            "Test num 831\n",
            "Test num 832\n",
            "Test num 834\n",
            "Test num 838\n",
            "Test num 839\n",
            "Test num 840\n",
            "Test num 842\n",
            "Test num 843\n",
            "Test num 844\n",
            "Test num 845\n",
            "Test num 846\n",
            "Test num 849\n",
            "Test num 850\n",
            "Test num 852\n",
            "Test num 854\n",
            "Test num 855\n",
            "Test num 856\n",
            "Test num 857\n",
            "Test num 858\n",
            "Test num 861\n",
            "Test num 862\n",
            "Test num 863\n",
            "Test num 866\n",
            "Test num 867\n",
            "Test num 868\n",
            "Test num 869\n",
            "Test num 870\n",
            "Test num 871\n",
            "Test num 873\n",
            "Test num 874\n",
            "Test num 876\n",
            "Test num 877\n",
            "Test num 880\n",
            "Test num 882\n",
            "Test num 883\n",
            "Test num 884\n",
            "Test num 885\n",
            "Test num 889\n",
            "Test num 890\n",
            "Test num 891\n",
            "Test num 896\n",
            "Test num 897\n",
            "Test num 903\n",
            "Test num 905\n",
            "Test num 907\n",
            "Test num 909\n",
            "Test num 910\n",
            "Test num 911\n",
            "Test num 912\n",
            "Test num 913\n",
            "Test num 916\n",
            "Test num 917\n",
            "Test num 918\n",
            "Test num 920\n",
            "Test num 922\n",
            "Test num 924\n",
            "Test num 925\n",
            "Test num 926\n",
            "Test num 929\n",
            "Test num 930\n",
            "Test num 933\n",
            "Test num 934\n",
            "Test num 935\n",
            "Test num 936\n",
            "Test num 938\n",
            "Test num 940\n",
            "Test num 941\n",
            "Test num 942\n",
            "Test num 944\n",
            "Test num 945\n",
            "Test num 947\n",
            "Test num 948\n",
            "Test num 951\n",
            "Test num 952\n",
            "Test num 953\n",
            "Test num 955\n",
            "Test num 956\n",
            "Test num 958\n",
            "Test num 960\n",
            "Test num 961\n",
            "Test num 962\n",
            "Test num 963\n",
            "Test num 964\n",
            "Test num 966\n",
            "Test num 969\n",
            "Test num 971\n",
            "Test num 973\n",
            "Test num 975\n",
            "Test num 976\n",
            "Test num 977\n",
            "Test num 981\n",
            "Test num 982\n",
            "Test num 984\n",
            "Test num 985\n",
            "Test num 986\n",
            "Test num 987\n",
            "Test num 988\n",
            "Test num 989\n",
            "Test num 992\n",
            "Test num 994\n",
            "Test num 995\n",
            "Test num 996\n",
            "Test num 998\n",
            "Test num 999\n",
            "Test num 1000\n",
            "Test num 1001\n",
            "Test num 1002\n",
            "Test num 1003\n",
            "Test num 1005\n",
            "Test num 1008\n",
            "Test num 1011\n",
            "Test num 1012\n",
            "Test num 1014\n",
            "Test num 1015\n",
            "Test num 1017\n",
            "Test num 1019\n",
            "Test num 1021\n",
            "Test num 1022\n",
            "Test num 1023\n",
            "\tTest Accuracy = 0 / 1024 = 0.0\n"
          ]
        }
      ],
      "source": [
        "#test c&W \n",
        "acc = test_carlini_wagner(net, valid_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got a final accuracy of 00 when we test on the basic model\n"
      ],
      "metadata": {
        "id": "RAHl9U7fzu5D"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "C&W Vs Basic model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}